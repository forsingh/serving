{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Serving in 10 minutes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow **SERVING** is Googles' recommended way to deploy TensorFlow models. Without proper computer engineering background, it can be quite intimidating, even for people who feel comfortable with TensorFlow itself. Few things that I've found particularly hard were:\n",
    "- Tutorial examples have C++ code (which I don't know)\n",
    "- Tutorials have Kubernetes, gRPG, Bezel (some of which I saw for the first time)\n",
    "- It needs to be compiled. That process takes forever!\n",
    "\n",
    "After all, it worked just fine. Here I present an easiest possible way to deploy your models with TensorFlow Serving. You will have your self-built model running inside TF-Serving by the end of this tutorial. It will be scalable, and you will be able to query it via REST.\n",
    "\n",
    "The Tutorial uses the Docker image. You can use Kitematic to start the image: **`avloss/tensorflow-serving-rest`**.\n",
    "\n",
    "*At first, I tried building it on \"DockerHub\" - but it hit the limit of 2 hours, so I had to use https://quay.io. I've uploaded finished result to DockerHub manually, but please feel free to pull from https://quay.io/repository/avloss/tensorflow-serving-rest in case you want to make sure it's what's it says it is.*\n",
    "\n",
    "You can start Docker Container from Kitematic, or use this command from console:\n",
    "\n",
    "`docker run --rm -it -p 8888:8888 -p 9000:9000 -p 8915:8915  quay.io/avloss/tensorflow-serving-rest`\n",
    "\n",
    "Once it's running, please navigate to http://localhost:8888/notebooks/tf_serving_rest_example.ipynb. (Use different port if using Kitematic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From here it's best to continue from within Jupyter Notebook!**\n",
    "\n",
    "To demonstrate how it's working, we are going to use the typical MNIST example from the official TF tutorial page:\n",
    "https://www.tensorflow.org/get_started/mnist/pros\n",
    "\n",
    "We instantiate a standard model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "\n",
    "y = tf.matmul(x,W) + b\n",
    "\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we declare `pred` value, which is the actual prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = tf.argmax(y,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We download training examples and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for _ in range(1000):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure that everything is working as expected. We have our number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa28919ae90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa2b4d55e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "number = mnist.train.next_batch(1)[0]\n",
    "\n",
    "plt.imshow(number.reshape(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that our model can efficiently predict it: \n",
    "\n",
    "*This example works 99% of the time! ;-)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(pred,feed_dict={x: number})[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to save this model, and serve it with TensorFlow Serving. We define the path where we store the weights and the model version.\n",
    "\n",
    "*Please note that you would need to increment `VERSION` number and re-create your graph (restart this notebook) if you want to save another model.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EXPORT_PATH = \"/tmp/models\"\n",
    "VERSION=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here we are saving the actual weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/tmp/models/00000001-tmp/export is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tmp/models/00000001'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.contrib.session_bundle import exporter\n",
    "\n",
    "saver = tf.train.Saver(sharded=True)\n",
    "model_exporter = exporter.Exporter(saver)\n",
    "model_exporter.init(\n",
    "    sess.graph.as_graph_def(),\n",
    "    named_graph_signatures={\n",
    "        'inputs': exporter.generic_signature({'x': x}),\n",
    "        'outputs': exporter.generic_signature({'pred': pred})})\n",
    "model_exporter.export(EXPORT_PATH, tf.constant(VERSION), sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure the weights were saved correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/models:\r\n",
      "total 12K\r\n",
      "drwxr-xr-x 2 root root 4.0K Mar 10 10:29 00000001\r\n",
      "-rw-r--r-- 1 root root 7.6K Mar 10 10:29 model.log\r\n",
      "\r\n",
      "/tmp/models/00000001:\r\n",
      "total 72K\r\n",
      "-rw-r--r-- 1 root root 119 Mar 10 10:29 checkpoint\r\n",
      "-rw-r--r-- 1 root root 31K Mar 10 10:29 export.data-00000-of-00001\r\n",
      "-rw-r--r-- 1 root root 159 Mar 10 10:29 export.index\r\n",
      "-rw-r--r-- 1 root root 29K Mar 10 10:29 export.meta\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lhR /tmp/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Services\n",
    "When this Docker Image started, it run `example_jupyter/setup.sh`. It started following services:\n",
    "\n",
    "\n",
    "- `jupyter notebook`\n",
    "\n",
    "This is jupyter notebook which we are using right now.\n",
    "\n",
    "\n",
    "- `/serving/bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server`\n",
    "\n",
    "This is TF Model Server running. It came as a part of TF-Serving standard distribution. It serves models using gRPC protocol.\n",
    "\n",
    "\n",
    "- `/serving/bazel-bin/tensorflow_serving/example/flask_client`\n",
    "\n",
    "I've added this Flask application to convert REST requests into gPRC requests. Perhaps this takes away from speed, but at least it's clear what is going on - you can find the code here: `tensorflow_serving/example/flask_client.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check TF Model Server. Until now it waited idly for a model to appear in that folder.\n",
    " We can now check the logs to make sure it recognised and loaded the model we just saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-03-10 10:29:49.461339: I tensorflow_serving/core/loader_harness.cc:86] Successfully loaded servable version {name: default version: 1}\r\n",
      "2017-03-10 10:29:49.464518: I tensorflow_serving/model_servers/main.cc:257] Running ModelServer at 0.0.0.0:9000 ...\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n2 /tmp/models/model.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REST request\n",
    "*Following part can run independently from what happened before - so you can run it in a different notebook, or on even on the host machine.*\n",
    "\n",
    "Here's an example of a function we can use to query our model via REST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import requests\n",
    "\n",
    "def test_flask_client(x):\n",
    "    URL = \"http://localhost:8915/model_prediction\"\n",
    "\n",
    "    s = pickle.dumps({\"x\":x}, protocol=0)\n",
    "\n",
    "    DATA = {\"model_name\": \"default\",\n",
    "            \"input\": requests.utils.quote(s)}\n",
    "\n",
    "    r = requests.get(URL, data=DATA)\n",
    "    return r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure our train data still makes sense:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa28d001050>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRfiBoAg/ENT/AyErW1pw/s8cAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa2b4d62390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "number = mnist.train.next_batch(1)[0]\n",
    "\n",
    "plt.imshow(number.reshape(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running prediction\n",
    "And finally - let's run a prediction on TensorFlow Serving!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'outputs': {u'pred': {u'dtype': u'DT_INT64',\n",
       "   u'int64Val': [u'7'],\n",
       "   u'tensorShape': {u'dim': [{u'size': u'1'}]}}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_flask_client(number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's easy to extract the actual prediction value from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(test_flask_client(number)[\"outputs\"][\"pred\"][\"int64Val\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done!\n",
    "\n",
    "And that's it! Now you got Docker Container which is running you TensorFlow model with Tensorflow Serving. This model can be queried via `REST` (as we just did), or via `gRPC` (port 9000).\n",
    "\n",
    "It is easy to export this as Docker Image so that it can be run elsewhere. In your host console do the following:\n",
    "\n",
    "`docker ps`\n",
    "\n",
    "It will show the ID of your running container. Use it in the following command (replace *XXXXXX* with *CONTAINER ID*)\n",
    "\n",
    "`docker commit XXXXXX  my_name/my_model:version1`\n",
    "\n",
    "`docker save my_name/my_model:version1 > my_name.my_model.version1.tar`\n",
    "\n",
    "Now your Docker image (with the model inside) is saved into a `tar` file, which you can easily move around. (I'm not suggesting that this is best practice, but it works). Once you got it to the server, do the following to run it:\n",
    "\n",
    "`docker load --input my_name.my_model.version1.tar`\n",
    "\n",
    "`docker run --rm -it -p 8888:8888 -p 9000:9000 -p 8915:8915  my_name/my_model:version1`\n",
    "\n",
    "And now you got your model running on a new server! Hope this works for you!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}